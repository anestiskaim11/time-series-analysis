{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U nolds matplotlib numpy pandas mpld3 statsmodels scikit-learn scipy git+https://github.com/manu-mannattil/nolitsa.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tonyt\\\\timeseries-codebase'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "%matplotlib auto\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from nolitsa import data, delay, dimension, d2, utils\n",
    "from mpl_toolkits import mplot3d\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample, arma_acf\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearfitnrmse(xV, m, Tmax=1, show=False):\n",
    "    ''' \n",
    "    % LINEARFITNRMSE fits an AR model and computes the fitting error\n",
    "    % for T-step ahead.\n",
    "    % INPUTS:\n",
    "    %  xV      : vector of the scalar time series\n",
    "    %  m       : the embedding dimension.\n",
    "    %  Tmax    : the prediction horizon, the fit is made for T=1...Tmax steps\n",
    "    %            ahead.\n",
    "    %  tittxt  : string to be displayed in the title of the figure \n",
    "    %            if not specified, no plot is made\n",
    "    % OUTPUT: \n",
    "    %  nrmseV  : vector of length Tmax, the nrmse of the fit for T-mappings, T=1...Tmax.\n",
    "    %  phiV    : the coefficients of the estimated AR time series (of length (m+1)\n",
    "    %            with phi(0) as first component\n",
    "    '''\n",
    "    from statsmodels.api import OLS\n",
    "\n",
    "    n = xV.shape[0]\n",
    "    mx = np.mean(xV[:n-Tmax+1])\n",
    "    yV = xV[:n-Tmax+1] - mx\n",
    "    nvec = n - m - 1 - Tmax\n",
    "    yM = np.full(shape=(nvec-1, m), fill_value=np.nan)\n",
    "    for j in np.arange(m):\n",
    "        yM[:, [m-j-1]] = yV[j:nvec+j-1]\n",
    "    rV = yV[j+1:nvec+j]\n",
    "    # np.linalg.lstsq(yM, rV)\n",
    "    ols = OLS(endog=rV, exog=yM).fit()\n",
    "    aV = ols.params\n",
    "    a0 = (1 - np.sum(aV)) * mx\n",
    "    phiV = np.r_[a0, aV]\n",
    "    preM = np.full(shape=(n+Tmax-1, Tmax), fill_value=np.nan)\n",
    "    for i in np.arange(m, n):\n",
    "        preV = np.full(shape=(m+Tmax, 1), fill_value=np.nan)\n",
    "        preV[:m] = xV[i-m: i] - mx\n",
    "        for T in np.arange(1, Tmax+1):\n",
    "            preV[m + T - 1] = np.dot(aV, (preV[T-1:m+T-1][::-1]))\n",
    "            preM[i + T - 1, [T-1]] = preV[m + T - 1]\n",
    "    preM = preM + mx\n",
    "    nrmseV = np.ones(shape=(Tmax, 1))\n",
    "    for T in np.arange(1, Tmax+1):\n",
    "        nrmseV[T-1] = nrmse(xV[m + T - 1:n], preM[m + T - 1: n, [T-1]])\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.plot(np.arange(1, Tmax+1), nrmseV, marker='x')\n",
    "        ax.set_xlabel('prediction time T')\n",
    "        ax.set_ylabel('NRMSE(T)')\n",
    "    return nrmseV, phiV\n",
    "\n",
    "def localfitnrmse(xV, tau, m, Tmax, nnei, q, show=''):\n",
    "    '''\n",
    "     LOCALFITNRMSE makes fitting using a local model of zeroth order (average \n",
    "    % mapping or nearest neighbor mappings if only one neighbor is chosen) or a \n",
    "    % local linear model and computes the fitting error for T-step ahead. For \n",
    "    % the search for neighboring points it uses the Matlab k-d-tree search.\n",
    "    % The fitting here means that predictions are made for all the points in\n",
    "    % the data set (in-sample prediction). The prediction error statistic \n",
    "    % (NRMSE measure) for the T-step ahead predictions is the goodness-of-fit \n",
    "    % statistic. \n",
    "    % The state space reconstruction is done with the method of delays having \n",
    "    % as parameters the embedding dimension 'm' and the delay time 'tau'. \n",
    "    % The local prediction model is one of the following:\n",
    "    % Ordinary Least Squares, OLS (standard local linear model): if the \n",
    "    % truncation parameter q >= m\n",
    "    % Principal Component Regression, PCR, project the parameter space of the \n",
    "    % model to only q of the m principal axes: if 0<q<m\n",
    "    % Local Average Mapping, LAM: if q=0.\n",
    "    % The local region is determined by the number of neighbours 'nnei'. \n",
    "    % The k-d-tree data structure is utilized to speed up computation time in \n",
    "    % the search of neighboring points and the implementation of Matlab is \n",
    "    % used. \n",
    "    % INPUTS:\n",
    "    %  xV      : vector of the scalar time series\n",
    "    %  tau     : the delay time (usually set to 1).\n",
    "    %  m       : the embedding dimension.\n",
    "    %  Tmax    : the prediction horizon, the fit is made for T=1...Tmax steps\n",
    "    %            ahead.\n",
    "    %  nnei    : number of nearest neighbors to be used in the local model. \n",
    "    %            If k=1,the nearest neighbor mapping is the fitted value. \n",
    "    %            If k>1, the model as defined by the input patameter 'q' is\n",
    "    %            used. \n",
    "    %  q       : the truncation parameter for a normalization of the local\n",
    "    %            linear model if specified (to project the parameter space of\n",
    "    %            the model, using Principal Component Regression, PCR, locally).\n",
    "    %            if q>=m -> Ordinary Least Squares, OLS (standard local linear\n",
    "    %                       model, no projection)\n",
    "    %            if 0<q<m -> PCR(q)\n",
    "    %            if q=0 -> local average model (if in addition nnei=1 ->\n",
    "    %            then the zeroth order model is applied)\n",
    "    %  tittxt  : string to be displayed in the title of the figure \n",
    "    %            if not specified, no plot is made\n",
    "    % OUTPUT: \n",
    "    %  nrmseV  : vector of length Tmax, the nrmse of the fit for T-mappings, \n",
    "    %            T=1...Tmax.\n",
    "    %  preM    : the matrix of size nvec x (1+Tmax) having the fit (in-sample\n",
    "    %            predictions) for T=1,...,Tmax, for each of the nvec \n",
    "    %            reconstructed points from the whole time series. The first\n",
    "    %            column has the time of the target point and the rest Tmax\n",
    "    %            columns the fits for T=1,...,Tmax time steps ahead.\n",
    "    '''\n",
    "    if q > m:\n",
    "        q = int(m)\n",
    "    n = xV.shape[0]\n",
    "\n",
    "    if n < 2 * (m-1)*tau - Tmax:\n",
    "        print('too short timeseries')\n",
    "        return\n",
    "\n",
    "    nvec = n - (m-1)*tau - Tmax\n",
    "    xM = np.full(shape=(nvec, m), fill_value=np.nan)\n",
    "\n",
    "    for j in np.arange(m):\n",
    "        xM[:, [m-j-1]] = xV[j*tau:nvec+j*tau]\n",
    "    from scipy.spatial import KDTree\n",
    "    kdtreeS = KDTree(xM)\n",
    "    preM = np.full(shape=(nvec, Tmax), fill_value=np.nan)\n",
    "    _, nneiindM = kdtreeS.query(xM, k=nnei+1, p=2)\n",
    "    nneiindM = nneiindM[:, 1:]\n",
    "    for i in np.arange(nvec):\n",
    "        neiM = xM[nneiindM[i]]\n",
    "        yV = xV[nneiindM[i] + m*tau]\n",
    "        if q == 0 or nnei == 1:\n",
    "            preM[i, 0] = np.mean(yV)\n",
    "        else:\n",
    "            mneiV = np.mean(neiM, axis=0)\n",
    "            my = np.mean(yV)\n",
    "            zM = neiM - mneiV\n",
    "            [Ux, Sx, Vx] = np.linalg.svd(zM, full_matrices=False)\n",
    "            Sx = np.diag(Sx)\n",
    "            Vx = Vx.T\n",
    "            tmpM = Vx[:, :q] @ (np.linalg.inv(Sx[:q, :q]) @ Ux[:, :q].T)\n",
    "            lsbV = tmpM @ (yV - my)\n",
    "            preM[i] = my + (xM[i, ] - mneiV) @ lsbV\n",
    "    if Tmax > 1:\n",
    "        winnowM = np.full(shape=(nvec, (m - 1) * tau + 1), fill_value=np.nan)\n",
    "        for i in np.arange(m*tau):\n",
    "            winnowM[:, [i]] = xV[i:nvec+i]\n",
    "        for T in np.arange(2, Tmax+1):\n",
    "            winnowM = np.concatenate([winnowM, preM[:, [T-2]]], axis=1)\n",
    "            targM = winnowM[:, :-(m+1)*tau:-tau]\n",
    "            _, nneiindM = kdtreeS.query(targM, k=nnei, p=2)\n",
    "\n",
    "            for i in np.arange(nvec):\n",
    "                neiM = xM[nneiindM[i], :]\n",
    "                yV = xV[nneiindM[i] + (m-1)*tau+1]\n",
    "                if q == 0 or nnei == 1:\n",
    "                    preM[i, T-1] = np.mean(yV)\n",
    "                else:\n",
    "                    mneiV = np.mean(neiM, axis=0)\n",
    "                    my = np.mean(yV)\n",
    "                    zM = neiM - mneiV\n",
    "                    [Ux, Sx, Vx] = np.linalg.svd(zM, full_matrices=False)\n",
    "                    Sx = np.diag(Sx)\n",
    "                    Vx = Vx.T\n",
    "                    tmpM = Vx[:, :q] @ (np.linalg.inv(Sx[:q, :q]) @ Ux[:, :q].T)\n",
    "                    lsbV = tmpM @ (yV - my)\n",
    "                    preM[i, T-1] = my + (targM[i, :] - mneiV) @ lsbV\n",
    "\n",
    "    nrmseV = np.full(shape=(Tmax, 1), fill_value=np.nan)\n",
    "    idx = (np.arange(nvec) + (m-1)*tau).astype(np.int)\n",
    "    for t_idx in np.arange(1, Tmax+1):\n",
    "        nrmseV[t_idx-1] = nrmse(trueV=xV[idx + t_idx, ], predictedV=preM[:, [t_idx-1]])\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.plot(np.arange(1, Tmax+1), nrmseV, marker='x')\n",
    "        ax.set_xlabel('prediction time T')\n",
    "        ax.set_ylabel('NRMSE(T)')\n",
    "    return nrmseV, preM\n",
    "\n",
    "def plot_timeseries(xV, get_histogram=False, title='', savepath=''):\n",
    "    # #plot timeseries\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "    ax.plot(xV, marker='x', linestyle='--', linewidth=2);\n",
    "    ax.set_xlabel('time')\n",
    "    ax.set_ylabel('value')\n",
    "    if len(title) > 0:\n",
    "        ax.set_title(title, x=0.5, y=1.0);\n",
    "    plt.tight_layout()\n",
    "    if len(savepath) > 0:\n",
    "        plt.savefig(f'{savepath}/{title}_xM.jpeg')\n",
    "    # #plot histogram\n",
    "    if get_histogram:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "        ax.hist(xV, alpha=0.8, rwidth=0.9);\n",
    "        ax.set_xlabel('value')\n",
    "        ax.set_title('Histogram')\n",
    "        plt.tight_layout()\n",
    "        if len(title) > 0:\n",
    "            ax.set_title(title, x=0.5, y=1.0);\n",
    "        plt.tight_layout()\n",
    "        if len(savepath) > 0:\n",
    "            plt.savefig(f'{savepath}/{title}_hist.jpeg')\n",
    "            \n",
    "def ANN(X, k):\n",
    "    '''\n",
    "    helper func\n",
    "    '''\n",
    "    tree = KDTree(X, leaf_size=1, metric='chebyshev')\n",
    "    dists, nnidx = tree.query(X, k=k)\n",
    "    del tree\n",
    "    return nnidx, dists\n",
    "\n",
    "def ANNR(X, rV):\n",
    "    '''\n",
    "    helper func\n",
    "    '''\n",
    "    tree = KDTree(X, leaf_size=1, metric='chebyshev')\n",
    "    nnnidx = tree.query_radius(X, r=rV, count_only=True)\n",
    "    return nnnidx\n",
    "\n",
    "def nneighforgivenr(X, rV):\n",
    "    '''\n",
    "    helper func\n",
    "    '''\n",
    "    npV = ANNR(X, rV)\n",
    "    npV[npV == 0] = 1\n",
    "    return npV\n",
    "\n",
    "\n",
    "def mi_estimator_ksg1(xV, yV, nnei=5, normalize=False):\n",
    "    '''\n",
    "    calculates I(X;Y) using KSG algorithm1 (with max-norms squares)\n",
    "    '''\n",
    "    from scipy.special import psi\n",
    "\n",
    "    n = xV.shape[0]\n",
    "    psi_nnei = psi(nnei)\n",
    "    psi_n = psi(n)\n",
    "\n",
    "    if normalize:\n",
    "        xV = (xV - np.min(xV)) / np.ptp(xV)\n",
    "        yV = (yV - np.min(yV)) / np.ptp(yV)\n",
    "\n",
    "    xembM = np.concatenate((xV, yV), axis=1)\n",
    "    _, distsM = ANN(xembM, nnei + 1)\n",
    "    maxdistV = distsM[:, -1]\n",
    "    n_x = nneighforgivenr(X=xV, rV=maxdistV - np.ones(n) * 10 ** (-10))\n",
    "    n_y = nneighforgivenr(X=yV, rV=maxdistV - np.ones(n) * 10 ** (-10))\n",
    "    psibothM = psi(np.concatenate((n_x.reshape(-1, 1), n_y.reshape(-1, 1)), axis=1))\n",
    "    #     # I(X;Y) = ψ(k) + ψ(Ν) - <ψ(Nx + 1) + ψ(Ny + 1)>\n",
    "    mi = psi_nnei + psi_n - np.mean(np.sum(psibothM, axis=1))\n",
    "    return mi\n",
    "\n",
    "def falsenearestneighbors(xV, m_max=10, tau=1, show=False):\n",
    "    dim = np.arange(1, m_max + 1)\n",
    "    f1, _, _ = dimension.fnn(xV, tau=tau, dim=dim, window=10, metric='cityblock')\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "        ax.scatter(dim, f1)\n",
    "        ax.axhline(0.01, linestyle='--', color='red', label='1% threshold')\n",
    "        ax.set_xlabel(f'm')\n",
    "        ax.set_title(f'FNN ({m_max})')\n",
    "        ax.set_xticks(dim)\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "    return f1\n",
    "\n",
    "def correlationdimension(xV, tau, mmax, fac=4, logrmin=-1e6, logrmax=1e6, show=False):\n",
    "    m_all = np.arange(1, m_max + 1)\n",
    "    corrdimV = []\n",
    "    logrM = []\n",
    "    logCrM = []\n",
    "    polyM = []\n",
    "\n",
    "    for m in m_all:\n",
    "        corrdim, *corrData = nolds.corr_dim(xV, m, debug_data=True)\n",
    "        corrdimV.append(corrdim)\n",
    "        logrM.append(corrData[0][0])\n",
    "        logCrM.append(corrData[0][1])\n",
    "        polyM.append(corrData[0][2])\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "        ax.plot(m_all, corrdimV, marker='x', linestyle='.-')\n",
    "        ax.set_xlabel('m')\n",
    "        ax.set_xticks(m_all)\n",
    "        ax.set_ylabel('v')\n",
    "        ax.set_title('Corr Dim vs m')\n",
    "        \n",
    "        \n",
    "    return corrdimV, logrM, logCrM, polyM\n",
    "       \n",
    "def split2train_testset(xV, test_proportion):\n",
    "    n = np.int(len(xV) * test_proportion)\n",
    "    return xV[:n], xV[n:]\n",
    "\n",
    "    \n",
    "def plot_3d_attractor(xM):\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(xM[:, 0], xM[:, 1], xM[:, 2])\n",
    "    ax.plot(xM[:, 0], xM[:, 1], xM[:, 2], linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "def embed_data(x, order=3, delay=1):\n",
    "    \"\"\"Time-delay embedding.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1d-array, shape (n_times)\n",
    "        Time series\n",
    "    order : int\n",
    "        Embedding dimension (order)\n",
    "    delay : int\n",
    "        Delay.\n",
    "    Returns\n",
    "    -------\n",
    "    embedded : ndarray, shape (n_times - (order - 1) * delay, order)\n",
    "        Embedded time-series.\n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    Y = np.empty((order, N - (order - 1) * delay))\n",
    "    for i in range(order):\n",
    "        Y[i] = x[i * delay:i * delay + Y.shape[1]]\n",
    "    return Y.T\n",
    "\n",
    "def logisticmap(n=1024, r=3., x0=None):\n",
    "    ntrans = 10\n",
    "    xV = np.full(shape=(n+ntrans, 1), fill_value=np.nan)\n",
    "    if x0 is None:\n",
    "        xV[0] = np.random.uniform(low=0, high=2.9)\n",
    "    else:\n",
    "        xV[0] = x0\n",
    "    for t in np.arange(1, n+ntrans):\n",
    "        xV[t] = r * xV[t-1] * (1 - xV[t-1])\n",
    "    xV = xV[ntrans:, [0]]\n",
    "    return xV.reshape(-1, )\n",
    "\n",
    "def generate_arma_ts(phiV, thetaV, n, sdnoise=1):\n",
    "    '''\n",
    "    Generate an ARMA(p,q) time series of length 'n' with Gaussian input noise.\n",
    "    Note that phiV = [phi(0) phi(1) ... phi(p)]' and phi(0) is the constant\n",
    "    term, and thetaV = [theta(1) ... theta(q)]'.\n",
    "    sdnoise is the SD of the input noise (if left out then sdnoise=1).\n",
    "    The generating ARMA(p,q) process reads\n",
    "    x(t) = phi(0) + phi(1)*x(t-1) + ... + phi(p)*x(t-p) +\n",
    "            +z(t) - theta(1)*z(t-1) + ... - theta(q)*z(t-p),\n",
    "    z(t) ~ WN(0,sdnoise^2)\n",
    "    '''\n",
    "    phiV = np.array(phiV)\n",
    "    thetaV = np.array(thetaV)\n",
    "    ar_params = np.r_[1, -phiV[:]]  # add zero lag\n",
    "    ma_params = np.r_[1, thetaV[:]]  # add zero lag\n",
    "    xV = arma_generate_sample(ar=ar_params, ma=ma_params, nsample=n, scale=sdnoise, burnin=100)\n",
    "    return xV\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f8a127400>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "x0 = 0.51\n",
    "r = 3.9\n",
    "xV = logisticmap(n=n, r=r, x0=x0)\n",
    "plt.figure()\n",
    "plt.plot(xV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20f8a21b4c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded = embed_data(xV, order=2, delay=1)\n",
    "# embedded;\n",
    "plt.scatter(xV[:-1], xV[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xV = generate_arma_ts([0.8], [0], n)\n",
    "plt.plot(xV);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20f8a7f16a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded = embed_data(xV, order=2, delay=1)\n",
    "# embedded;\n",
    "plt.scatter(xV[:-1], xV[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xM = data.henon();\n",
    "xM, xM.shape\n",
    "plt.plot(xM);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "xM = xM[:, 0]\n",
    "plt.plot(xM);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embed_data(xM, order=3, delay=1)\n",
    "embedded\n",
    "plot_3d_attractor(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REAL DATA ATTRACTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\tonyt\\\\timeseries-codebase')\n",
    "df = pd.read_csv('./data/BTCUSDT.csv')\n",
    "df.set_index(pd.to_datetime(df['time']), inplace=True)\n",
    "df.drop('time', axis=1, inplace=True)\n",
    "df = df['01-01-2020':'12-31-2021']\n",
    "df.plot();\n",
    "logreturns = df.apply(lambda x: np.log(x)).diff().bfill()\n",
    "logreturns.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embed_data(logreturns.values.reshape(-1,), order=2, delay=1)\n",
    "plt.scatter(embedded[:-1], embedded[1:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = pd.read_csv('./data/epileeg.dat')\n",
    "# eeg.plot();\n",
    "embedded = embed_data(eeg.values.reshape(-1,), order=3, delay=1)\n",
    "plot_3d_attractor(embedded)\n",
    "#plt.scatter(embedded[:-1], embedded[1:], linestyle='--', marker='x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for stationarity (Visual Inspection + statistical test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xM = xM[2900:3000]\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(xM);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-3.607788367273639, 0.005613864723952852, 8, 91, {'1%': -3.50434289821397, '5%': -2.8938659630479413, '10%': -2.5840147047458037}, 160.8991036546946)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf = adfuller(xM, maxlag=None)\n",
    "print(adf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute autocorrelation and delayed mutual information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'absolute_import', 'acorr', 'adfd', 'division', 'dmi', 'mi', 'np', 'print_function', 'utils']\n",
      "Help on function acorr in module nolitsa.delay:\n",
      "\n",
      "acorr(x, maxtau=None, norm=True, detrend=True)\n",
      "    Return the autocorrelation of the given scalar time series.\n",
      "    \n",
      "    Calculates the autocorrelation of the given scalar time series\n",
      "    using the Wiener-Khinchin theorem.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        1-D real time series of length N.\n",
      "    maxtau : int, optional (default = N)\n",
      "        Return the autocorrelation only up to this time delay.\n",
      "    norm : bool, optional (default = True)\n",
      "        Normalize the autocorrelation so that it is equal to 1 for\n",
      "        zero time delay.\n",
      "    detrend: bool, optional (default = True)\n",
      "        Subtract the mean from the time series (i.e., a constant\n",
      "        detrend).  This is done so that for uncorrelated data, the\n",
      "        autocorrelation vanishes for all nonzero time delays.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    r : array\n",
      "        Array with the autocorrelation up to maxtau.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dir(delay))\n",
    "help(delay.acorr)\n",
    "xM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.         -0.29794006  0.28266378 -0.39795127  0.05296598 -0.20216741\n",
      " -0.09171786  0.19458939 -0.07892186  0.34396883]\n",
      "Autocorrelation time = 1\n"
     ]
    }
   ],
   "source": [
    "maxtau = 10\n",
    "lag = np.arange(maxtau)\n",
    "r = delay.acorr(xM, maxtau=maxtau)\n",
    "i = delay.dmi(xM, maxtau=maxtau)\n",
    "r_delay = np.argmax(r < 1.0 / np.e)\n",
    "\n",
    "plt.figure(1, figsize=(14, 8))\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(r'Delay estimation for Henon map')\n",
    "plt.ylabel(r'Delayed mutual information')\n",
    "plt.plot(lag, i, marker='o')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.xlabel(r'Time delay $\\tau$')\n",
    "plt.ylabel(r'Autocorrelation')\n",
    "plt.plot(lag, r, r_delay, r[r_delay], 'o')\n",
    "plt.axhline(1.0 / np.e, linestyle='--', alpha=0.7, color='red' )\n",
    "\n",
    "\n",
    "plt.figure(2, figsize=(14, 8))\n",
    "plt.subplot(111)\n",
    "plt.title(r'Time delay = %d' % r_delay)\n",
    "plt.xlabel(r'$x(t)$')\n",
    "plt.ylabel(r'$x(t + \\tau)$')\n",
    "plt.plot(xM[:-r_delay], xM[r_delay:], '.')\n",
    "\n",
    "plt.show()\n",
    "print(r)\n",
    "print(r'Autocorrelation time = %d' % r_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = np.arange(1, 10 + 1)\n",
    "f1, f2, f3 = dimension.fnn(xM, tau=1, dim=dim, window=10, metric='cityblock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(r'FNN for Henon map')\n",
    "plt.xlabel(r'Embedding dimension $d$')\n",
    "plt.ylabel(r'FNN (%)')\n",
    "plt.plot(dim, 100 * f1, 'bo--', label=r'Test I')\n",
    "plt.plot(dim, 100 * f2, 'g^--', label=r'Test II')\n",
    "plt.plot(dim, 100 * f3, 'rs-', label=r'Test I + II')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\utils.py:230: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray([result.get() for result in results])\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n",
      "C:\\Users\\tonyt\\anaconda3\\lib\\site-packages\\nolitsa\\d2.py:185: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  d[i] = np.linalg.lstsq(A, q)[0][0]\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.title('Local $D_2$ vs $r$ for Henon map')\n",
    "plt.xlabel(r'Distance $r$')\n",
    "plt.ylabel(r'Local $D_2$')\n",
    "theiler_window = 10\n",
    "tau = 1\n",
    "dim = np.arange(1, 10 + 1)\n",
    "\n",
    "for r, c in d2.c2_embed(xM, tau=tau, dim=dim, window=theiler_window,\n",
    "                        r=utils.gprange(0.001, 1.0, 100)):\n",
    "    plt.semilogx(r[3:-3], d2.d2(r, c), color='#4682B4')\n",
    "\n",
    "plt.semilogx(utils.gprange(0.001, 1.0, 100), 1.220 * np.ones(100),\n",
    "             color='#000000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nolds\n",
    "r = utils.gprange(0.001, 1.0, 100)\n",
    "corr_dim, debug_data = nolds.corr_dim(xM, emb_dim=2, rvals=r, debug_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvals = debug_data[0] #values used for log(r)\n",
    "csums = debug_data[1] #the corresponding log(C(r))\n",
    "poly = debug_data[2] #line coefficients ([slope, intercept])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'log(C(r))')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(rvals, csums)\n",
    "ax.set_xlabel('log(r)')\n",
    "ax.set_ylabel('log(C(r))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "- LAP\n",
    "- LLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = xM.shape[0]\n",
    "test_prop = 0.3\n",
    "split_point = int(n * (1 - test_prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xM = xM[:split_point]\n",
    "test_xM = xM[split_point:]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(np.arange(split_point), train_xM, color='blue', alpha=0.7, label='train set');\n",
    "plt.plot(np.arange(split_point, xM.shape[0]), test_xM, color='red', linestyle='--', alpha=0.7, label='test set');\n",
    "plt.legend()\n",
    "plt.xlabel('Time');\n",
    "plt.ylabel('Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "embed_train_data = embed_data(train_xM, 2, 1)\n",
    "embed_test_data = embed_data(test_xM, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = 5\n",
    "tree = KDTree(embed_train_data, leaf_size=1, metric='chebyshev')\n",
    "neighbors_idx = []\n",
    "for i, state in enumerate(embed_test_data):\n",
    "    dist, neigh_idx = tree.query(state.reshape(1, -1), k=knn)\n",
    "    neighbors_idx.append(tuple([i, neigh_idx[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, array([49,  4, 13, 62, 47], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20f8a3a18b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(xM)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('xM')\n",
    "plt.axvline(split_point, linestyle='--', color='black', alpha=0.5)\n",
    "# #get neighbors of first test datapoint  \n",
    "check_test_point = 1\n",
    "neigh = neighbors_idx[check_test_point]\n",
    "print(neigh)\n",
    "test_state_idx = neigh[0]\n",
    "neighs_idx = neigh[1]\n",
    "plt.plot([neighs_idx, neighs_idx+1], [xM[neighs_idx], xM[neighs_idx+1]], linestyle='--', color='orange' )\n",
    "plt.scatter([neighs_idx, neighs_idx+1], [xM[neighs_idx], xM[neighs_idx+1]], linestyle='--', color='orange')\n",
    "# #test set state\n",
    "plt.plot([test_state_idx+split_point, test_state_idx+split_point+1], [xM[test_state_idx+split_point], xM[test_state_idx+split_point+1]], linestyle='--', color='red' )\n",
    "plt.scatter([test_state_idx+split_point, test_state_idx+split_point+1], [xM[test_state_idx+split_point], xM[test_state_idx+split_point+1]], linestyle='--', color='red')\n",
    "    \n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(embed_train_data[:, 0], embed_train_data[:, 1], alpha=0.3)\n",
    "plt.scatter(embed_train_data[neighs_idx][:, 0], embed_train_data[neighs_idx][:, 1], label=f'neighbors in train data')\n",
    "plt.scatter(embed_test_data[test_state_idx, 0], embed_test_data[test_state_idx, 1], label=f'test point:{test_state_idx}')\n",
    "plt.xlabel('x(t)')\n",
    "plt.ylabel('x(t+1)')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f8a5eb100>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 1;\n",
    "lap_predictions = []\n",
    "for neigh in neighbors_idx:\n",
    "    test_state_idx = neigh[0]\n",
    "    neighs_idx = neigh[1]\n",
    "    images_idx = neighs_idx + T\n",
    "    images = xM[images_idx]\n",
    "    lap = np.sum(images) / len(images)\n",
    "    lap_predictions.append(lap)\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(np.arange(split_point+1, xM.shape[0]), lap_predictions, label='LAP prediction', alpha=0.9, linestyle='-.')\n",
    "plt.plot(np.arange(split_point+1, xM.shape[0]), test_xM[1:,], label='True values', alpha=0.9, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06719410124856373"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((np.array(lap_predictions) -  test_xM[1:,])**2))/np.std(test_xM[1:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only implemented for 2-dimensional arrays",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5152e9ace27c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\tools.py\u001b[0m in \u001b[0;36madd_constant\u001b[1;34m(data, prepend, has_constant)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Only implemented for 2-dimensional arrays'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[0mis_nonzero_const\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mptp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only implemented for 2-dimensional arrays"
     ]
    }
   ],
   "source": [
    "X, y = [], []\n",
    "for neigh in neigh_idx:\n",
    "    x_ =  [xM[neigh], xM[neigh+1]]\n",
    "    y_ = [xM[neigh+1+T]]\n",
    "    X.append(x_)\n",
    "    y.append(y_)\n",
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "ols = sm.OLS(endog=y, exog=X).fit()\n",
    "llp = np.dot(ols.params, [1, xM[i+split_point], xM[i+split_point+1]])\n",
    "ols.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/epileeg.dat', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "xM = np.full(shape=len(lines), fill_value=np.nan)\n",
    "for i, line in enumerate(lines):\n",
    "    point = line.rstrip().lstrip()\n",
    "    xM[i] = point\n",
    "xM = np.array(xM)\n",
    "xM\n",
    "plt.plot(xM)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
